apiVersion: keda.sh/v1alpha1
kind: ScaledObject
metadata:
  name: health-service-scaledobject
  namespace: default
  labels:
    app: health-service
    scaler: prometheus
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: health-service

  minReplicaCount: 2
  maxReplicaCount: 10
  cooldownPeriod: 30
  pollingInterval: 15

  advanced:
    horizontalPodAutoscalerConfig:
      behavior:
        scaleUp:
          stabilizationWindowSeconds: 0
          policies:
            - type: Percent
              value: 100
              periodSeconds: 15
            - type: Pods
              value: 4
              periodSeconds: 15
          selectPolicy: Max

        scaleDown:
          stabilizationWindowSeconds: 30
          policies:
            - type: Percent
              value: 50
              periodSeconds: 15
          selectPolicy: Max

  triggers:
    # RPS per pod
    - type: prometheus
      metadata:
        serverAddress: http://prometheus-prometheus.monitoring.svc.cluster.local:9090
        metricName: nginx_http_requests_rate
        threshold: "100"
        query: |
          sum(rate(nginx_ingress_controller_requests{
            namespace="default",
            service="health-service"
          }[2m])) /
          count(kube_pod_status_ready{
            namespace="default",
            pod=~"health-service.*",
            condition="true"
          })

    # P95 latency (ms)
    - type: prometheus
      metadata:
        serverAddress: http://prometheus-prometheus.monitoring.svc.cluster.local:9090
        metricName: nginx_http_latency_p95
        threshold: "500"
        query: |
          histogram_quantile(0.95,
            sum(rate(nginx_ingress_controller_request_duration_seconds_bucket{
              namespace="default",
              service="health-service"
            }[5m])) by (le)
          ) * 1000

    # Active connections per pod
    - type: prometheus
      metadata:
        serverAddress: http://prometheus-prometheus.monitoring.svc.cluster.local:9090
        metricName: nginx_active_connections
        threshold: "50"
        query: |
          sum(nginx_ingress_controller_nginx_process_connections{
            state="active"
          }) /
          count(kube_pod_status_ready{
            namespace="default",
            pod=~"health-service.*",
            condition="true"
          })

    # CPU %
    - type: prometheus
      metadata:
        serverAddress: http://prometheus-prometheus.monitoring.svc.cluster.local:9090
        metricName: health_service_cpu_utilization
        threshold: "70"
        query: |
          avg(
            rate(container_cpu_usage_seconds_total{
              namespace="default",
              pod=~"health-service.*",
              container="health-service"
            }[2m])
          ) * 100 /
          avg(
            kube_pod_container_resource_requests{
              namespace="default",
              pod=~"health-service.*",
              container="health-service",
              resource="cpu"
            }
          )

    # Memory %
    - type: prometheus
      metadata:
        serverAddress: http://prometheus-prometheus.monitoring.svc.cluster.local:9090
        metricName: health_service_memory_utilization
        threshold: "80"
        query: |
          avg(
            container_memory_working_set_bytes{
              namespace="default",
              pod=~"health-service.*",
              container="health-service"
            }
          ) * 100 /
          avg(
            kube_pod_container_resource_requests{
              namespace="default",
              pod=~"health-service.*",
              container="health-service",
              resource="memory"
            }
          )
